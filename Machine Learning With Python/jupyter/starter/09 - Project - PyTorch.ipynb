{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef5edb03",
   "metadata": {},
   "source": [
    "### Step 1: Install Torch\n",
    "- Execute the following cell which will install **torch** and **torchvision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3086f8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b8bc9a2",
   "metadata": {},
   "source": [
    "### Step 2: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d96fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb3a4ae5",
   "metadata": {},
   "source": [
    "### Step 3: Download the CIFAR10 dataset\n",
    "- Excute the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73edbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd1bd0ca",
   "metadata": {},
   "source": [
    "### Step 4: Explore the dataset\n",
    "- See the type of **cifar10**\n",
    "- Get the length of **cifar10**\n",
    "- Assign image and label of **cifar10** at index 1000\n",
    "- Get the class name of label\n",
    "    - HINT: Use **cifar10.classes[label]** to get the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfa245d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c1319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23105a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab645542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65639015",
   "metadata": {},
   "source": [
    "### Step 5: Visualize the image\n",
    "- Use **matplotlib** to visuazlize image\n",
    "    - HINT: just use **plt.imshow(...)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7972f5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31377c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8005d75d",
   "metadata": {},
   "source": [
    "### Step 6: Transform images\n",
    "- We need to convert the PIL image to a PyTorch tensor\n",
    "- We can easily transform it by adding **transform=transforms.ToTensor()** when reading the dataset.\n",
    "- This is given below (just execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7ff28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfaae34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe65a981",
   "metadata": {},
   "source": [
    "### Step 7: Normalize images\n",
    "- Now you have all images (transformed) in **tensor_cifar10**.\n",
    "- To concatenate a stack of images use **torch.stack(..., dim=3)** on the images\n",
    "    - HINT: Use list comprehension to get a list of images from **tensor_cifar10** (to exclude labels)\n",
    "- Calculate the **mean(dim=1)** by applying it on the stack\n",
    "- Calculate the **std(dim=1)** by applying it on the stack\n",
    "- We will use the results in next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab100f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb9d040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c211f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d298703f",
   "metadata": {},
   "source": [
    "### Step 8: Normalize the data\n",
    "- We can add a normalize transform with adding a **transforms.Compose([...])**, where the list will contain the transforms.\n",
    "- The transform we want are **transforms.ToTensor()** and **transforms.Normalize(...)**\n",
    "    - HINT: See lesson how it was done\n",
    "- The **transforms.Normalize(...)** takes two tuples of the results from last step.\n",
    "    - Note: that in the lesson it was single numbers, here we hare tuples.\n",
    "- Read the datasets to **cifar10** with the new transform\n",
    "- Read the validation dataset to **cifar10_val** with the new transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64a4606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d716038d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1ef2dcd",
   "metadata": {},
   "source": [
    "### Step 9: Limit the dataset\n",
    "- There are 10 classes in this dataset - to simplify, we will reduce it to two\n",
    "- We will keep label 0 and 2 (**'airplane'** and **'bird'**)\n",
    "- Use list comprehension to filter the datasets.\n",
    "    - To simplify use a **label_map = {0: 0, 2: 1}**, which is used to map label 0 to 0 and label 2 to 1.\n",
    "    - Then use list comprehension **[(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]**\n",
    "    - And similar for **cifar10_val**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90047549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1fb39f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60bb3eac",
   "metadata": {},
   "source": [
    "### Step 10: Create the model\n",
    "- We create a simple model here\n",
    "    - 3072 input nodes -> Linear with 512 nodes (Tanh acitivation)  -> Linear with 2 nodes (LogSoftmax activation)\n",
    "- To do that use **nn.Sequential(...)** with the following arguments.\n",
    "    - **nn.Linear(3072, 512)**\n",
    "        - Bonus question: Why 3072 input nodes?\n",
    "    - **nn.Tanh()**\n",
    "    - **nn.Linear(512, 2)**\n",
    "    - **nn.LogSoftmax(dim=1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eafc651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a5f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf32440f",
   "metadata": {},
   "source": [
    "### Step 11: Train the model\n",
    "- Prepare training data\n",
    "\n",
    "```Python\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "```\n",
    "\n",
    "- Set the **learning_rate = 0.01** (to make it easy to adjust)\n",
    "- Prepare optimizer and loss function.\n",
    "\n",
    "```Python\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "```\n",
    "\n",
    "- Run the training\n",
    "\n",
    "```Python\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a790adfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3297c63d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92a127ed",
   "metadata": {},
   "source": [
    "### Step 12: Test the model\n",
    "- Run the following code (where we assume the test data is called **cifar10_val** and the model **model**.\n",
    "```Python\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "print(\"Accuracy: %f\", correct / total)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ad0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b133acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99161df7",
   "metadata": {},
   "source": [
    "### Step 13 (Optional): Improve the model\n",
    "- Try to improve the model\n",
    "    - Simple things you can play with\n",
    "        - Adjust the learning rate\n",
    "        - Run more epochs\n",
    "        - Number of hidden nodes\n",
    "    - Medium things to play with\n",
    "        - Change activation functions\n",
    "        - Add another layer\n",
    "    - Advanced things\n",
    "        - Let your imagination guide you\n",
    "        - For inspiration see state of the art results ([wiki](https://en.wikipedia.org/wiki/CIFAR-10#Research_papers_claiming_state-of-the-art_results_on_CIFAR-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77dac86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69774be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f103c9c",
   "metadata": {},
   "source": [
    "### Step 14 (Optional): Add more classes\n",
    "- The dataset was limited to two classes (**airplane**s and **bird**s)\n",
    "- Try to add another class (or more) and see how it changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65c060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37e5bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
