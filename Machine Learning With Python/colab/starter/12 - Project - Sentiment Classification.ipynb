{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9b5111",
   "metadata": {},
   "source": [
    "<a \n",
    " href=\"https://colab.research.google.com/github/LearnPythonWithRune/MachineLearningWithPython/blob/main/colab/starter/12 - Project - Sentiment Classification.ipynb\"\n",
    " target=\"_parent\">\n",
    "<img \n",
    " src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
    "alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229fa4f2",
   "metadata": {},
   "source": [
    "# Project: Sentiment Classification\n",
    "- Make a model to determine whether a tweet positive or negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd592d25",
   "metadata": {},
   "source": [
    "### Step 1: Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21ee086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c6e9000",
   "metadata": {},
   "source": [
    "### Step 2: Download the sample tweets\n",
    "- Execute the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251297d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feccae3b",
   "metadata": {},
   "source": [
    "### Step 3: The tweets\n",
    "- Get the positive and negative tweets.\n",
    "    - HINT: You access the positive tweets by: **nltk.corpus.twitter_samples.strings('positive_tweets.json')**\n",
    "    - HINT: Similarly for the negative tweets.\n",
    "- Notice: There is also tweets with no sentiment - we will ignore them in this project\n",
    "- Check a few tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfd4b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82e551b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fac2b506",
   "metadata": {},
   "source": [
    "### Step 4: Tokenize the tweets\n",
    "- You get the tokenized tweets as follows:\n",
    "    - **nltk.corpus.twitter_samples.tokenized('positive_tweets.json')**\n",
    "    - Simlarly for **negative_tweets**\n",
    "- Why tokenize?\n",
    "    - To make processing easier\n",
    "- Check a few tweets (tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8087dc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f29e5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cce77587",
   "metadata": {},
   "source": [
    "### Step 5: Remove noise from data\n",
    "- The following tokens do not add value in our analysis\n",
    "    - Twitter usernames (starting with @)\n",
    "    - Hyperlinks (starting with http:// or https://)\n",
    "    - Punctuation and special characters\n",
    "        - HINT: if word in **string.punctuation**\n",
    "    - Numeric values only\n",
    "        - HINT: use **.isnumeric()**\n",
    "    - If word is a stopword ([wiki](https://en.wikipedia.org/wiki/Stop_word))\n",
    "        - HINT: Check if lower case word is in **stopwords.words('english')**\n",
    "- To simplify createa a helper function **is_clean** to check for the above\n",
    "- Create another helper function **clean_tokens**\n",
    "    - The function takes **tokens** (a list of tokens) as input\n",
    "    - Then returns a list of tokens, where **is_clean** has been used to filter\n",
    "    - Also, let's lowercase it all\n",
    "        - HINT: Use **lower()**\n",
    "- Finally, use list comprehension on the lists of positive and negative tweets where **clean_tokens** is applied on each element (tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac9e10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea158ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e303d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84a5141e",
   "metadata": {},
   "source": [
    "### Step 6: Normalize the data\n",
    "- The process of converting a word to its canonical form.\n",
    "- Without normalization, “ran”, “runs”, and “running” would be treated as different words.\n",
    "- Create a lemmatizer of **WordNetLemmatizer()**\n",
    "    - HINT: use **lemmatizer = WordNetLemmatizer()**\n",
    "- Create a helper function to lemmatize\n",
    "    - HINT: Create a helper function **lemmatize(word, tag)**\n",
    "        - Convert tag to **n** or **v** if tag starts with **NN** or **VB**, else **a**\n",
    "        - Return **lemmatizer.lemmatize(word, tag)**\n",
    "- Create a helper function **lemmatize_tokens(tokens: list)**\n",
    "    - Return a list, where each element of **word, tag in pos_tag(...)** of **lemmatize(word, tag)**.\n",
    "- Use list comprehension to normalize the positive and negative tweets\n",
    "    - HINT: apply **lemmatize_tokens(...)** on all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dda924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44845a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df8c175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ef7fc28",
   "metadata": {},
   "source": [
    "### Step 7: Prepare data for Model\n",
    "- Example of normalized tweet: **['hopeless', 'tmr', ':(']**\n",
    "    - Should become **({'hopeless': True, 'tmr': True, ':(': True}, 'Negative')**\n",
    "- Hence, the list of tweets (positive and negative) should be converted\n",
    "- HINT: use a dict comprehension inside a list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbdfcbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59426632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0192fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdb20c6b",
   "metadata": {},
   "source": [
    "### Step 8: Prepare training and test dataset\n",
    "- Make the dataset of the combined positive and negative datasets\n",
    "- Shuffle the dataset\n",
    "    - Use **shuffle**\n",
    "- Let the training dataset be the first 7000 entries\n",
    "- Let the test dataset be the remaining entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389612ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d21b383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a776bf28",
   "metadata": {},
   "source": [
    "### Step 9: Train and test Model\n",
    "- Train the model:\n",
    "    - HINT: **classifier = NaiveBayesClassifier.train(train_data)**\n",
    "- Test the accuracy\n",
    "    - HINT: **classify.accuracy(classifier, test_data)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce459f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f544e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8b47f6d",
   "metadata": {},
   "source": [
    "### Step 10: Show the most informative features\n",
    "- HINT: Get the 10 most informative features: **classifier.show_most_informative_features(10)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6318244b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac7cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9087a7d5",
   "metadata": {},
   "source": [
    "### Step 11: Test the model\n",
    "- Try your model as follows:\n",
    "    - Define a tweet: **tweet = 'this is fun and awesome'**\n",
    "    - Prepare data for model: **tweet_dict = {token: True for token in lemmatize_tokens(clean_tokens(tweet.split()))}**\n",
    "    - Classify data: **classifier.classify(tweet_dict)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a945de62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799de693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46b1dd34",
   "metadata": {},
   "source": [
    "### Bonus: The pre-trained Sentiment Intensity Analyzer\n",
    "-  VADER (Valence Aware Dictionary and sEntiment Reasoner) ([Vader](https://www.nltk.org/howto/sentiment.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6880b4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70716b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4946af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2094acb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
