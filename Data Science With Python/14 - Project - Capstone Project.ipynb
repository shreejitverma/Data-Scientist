{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39c877c9",
   "metadata": {},
   "source": [
    "# Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26869a35",
   "metadata": {},
   "source": [
    "![Data Science Workflow](img/ds-workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5dd4d3",
   "metadata": {},
   "source": [
    "## Goal of Project\n",
    "- This is the **Capstone Project** where we put it all together\n",
    "- Ideally, we would look at a real business/organisation problem and turn it into a **Data Science Problem**\n",
    "- As this can be hard, we will just assume we have a problem that we need to sovle\n",
    "- This will be done by either making up a problem or looking at some data that interests you and make up a question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f362c4",
   "metadata": {},
   "source": [
    "## Step 1: Acquire\n",
    "- Explore problem\n",
    "- Identify data\n",
    "- Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37d96e5",
   "metadata": {},
   "source": [
    "### Step 1.a: Define Problem\n",
    "- This is fictional - but assume you are your customer first\n",
    "- When trying to define a problem, don't be too ambitious\n",
    "    - Examples:\n",
    "        - A green energy windmill producer need to optimize distribution and need better prediction on production based on weather forecasts\n",
    "        - An online news media is interested in a story with how CO2 per capita around the world has evolved over the years\n",
    "    - Both projects are difficult\n",
    "        - For the windmill we would need data on production, maintenance periods, detailed weather data, just to get started.\n",
    "        - The data for CO2 per capita is available on [World Bank](https://data.worldbank.org/indicator/EN.ATM.CO2E.PC), but creating a visual story is difficult with our current capabilities\n",
    "- Hence, make a better research problem\n",
    "    - You can start by considering a dataset and get inspiration\n",
    "    - Examples of datasets\n",
    "        - `files/soccer.parquet`\n",
    "        - `files/co2_gdp_per_capita.csv`\n",
    "        - [Kaggle: IMDb movies extensive dataset](https://www.kaggle.com/stefanoleone992/imdb-extensive-dataset)\n",
    "        - See places to find data in Lesson\n",
    "    - Example of Problem\n",
    "        - What is the highest rated movie genre?\n",
    "        \n",
    "#### Data Science: Understanding the Problem\n",
    "- Get the right question:\n",
    "    - What is the **problem** we try to **solve**?\n",
    "    - This forms the **Data Science problem**\n",
    "    - **Examples**\n",
    "        - Sales figure and call center logs: evaluate a new product\n",
    "        - Sensor data from multiple sensors: detect equipment failure\n",
    "        - Customer data + marketing data: better targeted marketing\n",
    "- **Assess situation**\n",
    "    - Risks, Benefits, Contingencies, Regulations, Resources, Requirement\n",
    "- **Define goal**\n",
    "    - What is the **objective**?\n",
    "    - What is the **success criteria**?\n",
    "- **Conclusion**\n",
    "    - Defining the problem is key to successful Data Science projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8897973b",
   "metadata": {},
   "source": [
    "#### Sample project:\n",
    "An online media wants to write an article on the trend of movies ratings over the time. They want to explore what is the overall trend and are there different trends in different genres.\n",
    "- They ask you to make some charts showing trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8711f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f8cbbcb",
   "metadata": {},
   "source": [
    "### Step 1.b: Import libraries\n",
    "- Execute the cell below (SHIFT + ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c78d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f9a799",
   "metadata": {},
   "source": [
    "### Step 1.c: Identify the Data\n",
    "\n",
    "#### Great Places to Find Data ([Lesson 05]())\n",
    "- [UC Irvine Machine Learning Repository!](https://archive.ics.uci.edu/ml/index.php)\n",
    "- [KD Nuggets](https://www.kdnuggets.com/datasets/index.html) Datasets for Data Mining, Data Science, and Machine Learning\n",
    "    - [KD Nuggets](https://www.kdnuggets.com/datasets/government-local-public.html) Government, State, City, Local and Public\n",
    "    - [KD Nuggets](https://www.kdnuggets.com/datasets/api-hub-marketplace-platform.html) APIs, Hubs, Marketplaces, and Platforms\n",
    "    - [KD Nuggets](https://www.kdnuggets.com/competitions/index.html) Analytics, Data Science, Data Mining Competitions\n",
    "- [data.gov](https://www.data.gov) The home of the U.S. Government’s open data\n",
    "- [data.gov.uk](https://data.gov.uk) Data published by central government\n",
    "- [World Health Organization](https://www.who.int/data/gho) Explore a world of health data\n",
    "- [World Bank](https://data.worldbank.org) source of world data\n",
    "- [Kaggle](https://www.kaggle.com) is an online community of data scientists and machine learning practitioners.\n",
    "\n",
    "#### Sample project\n",
    "- Example could be files in `files/imdb/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65890ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d1b0478",
   "metadata": {},
   "source": [
    "### Step 1.d: Import Data\n",
    "####  Read CSV files *(Lesson 05)*\n",
    "- Comma-Seperated Values ([Wikipedia]https://en.wikipedia.org/wiki/Comma-separated_values))\n",
    "-  Learn more about Excel processing [in this YouTube lesson on CSV](https://youtu.be/LEyojSOg4EI)\n",
    "- [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html): read a comma-separated values (csv) file into **pandas** DataFrame.\n",
    "```Python\n",
    "import pandas as pd\n",
    "data = pd.read_csv('files/aapl.csv', parse_dates=True, index_col=0)\n",
    "```\n",
    "\n",
    "#### Excel files *(Lesson 05)*\n",
    "- Most videly used [spreadsheet](https://en.wikipedia.org/wiki/Spreadsheet)\n",
    "- Learn more about Excel processing [in this lecture](https://www.learnpythonwithrune.org/csv-groupby-processing-to-excel-with-charts-using-pandas-python/)\n",
    "- [`read_excel()`](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html) Read an Excel file into a pandas DataFrame.\n",
    "```Python\n",
    "data = pd.read_excel('files/aapl.xlsx', index_col='Date')\n",
    "```\n",
    "\n",
    "#### Parquet files *(Lesson 05)*\n",
    "- [Parquet](https://en.wikipedia.org/wiki/Apache_Parquet) is a free open source format\n",
    "- Compressed format\n",
    "- [`read_parquet()`](https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html) Load a parquet object from the file path, returning a DataFrame.\n",
    "```Python\n",
    "data = pd.read_parquet('files/aapl.parquet')\n",
    "```\n",
    "\n",
    "#### Web Scraping *(Lesson 03)*\n",
    "- Extracting data from websites\n",
    "- Leagal issues: [wikipedia.org](https://en.wikipedia.org/wiki/Web_scraping#Legal_issues)\n",
    "- [`read_html()`](https://pandas.pydata.org/docs/reference/api/pandas.read_html.html) Read HTML tables into a list of DataFrame objects.\n",
    "```Python\n",
    "url = \"https://en.wikipedia.org/wiki/Wikipedia:Fundraising_statistics\"\n",
    "data = pd.read_html(url)\n",
    "```\n",
    "\n",
    "#### Databases *(Lesson 04)*\n",
    "- [`read_sql()`](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html) Read SQL query or database table into a DataFrame.\n",
    "- The [sqlite3](https://docs.python.org/3/library/sqlite3.html) is an interface for SQLite databases.\n",
    "```Python\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect('files/dallas-ois.sqlite')\n",
    "data = pd.read_sql('SELECT * FROM officers', conn)\n",
    "```\n",
    "\n",
    "#### Sample project\n",
    "- If using `files/imdb/` they are stored as `parquet`\n",
    "    - HINT: Use `pd.read_parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99877b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36533a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b991bfd",
   "metadata": {},
   "source": [
    "### Step 1.e: Combine data\n",
    "- Often you need to combine data\n",
    "- Often we need to combine data from different sources\n",
    "\n",
    "#### pandas DataFrames\n",
    "- pandas DataFrames can combine data ([pandas cheat sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf))\n",
    "- `concat([df1, df2], axis=0)`: [concat](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) Concatenate pandas objects along a particular axis \n",
    "- `df.join(other.set_index('key'), on='key')`: [join](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html) Join columns of another DataFrame.\n",
    "- `df1.merge(df2, how='inner', on='a')` [merge](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) Merge DataFrame or named Series objects with a database-style join\n",
    "\n",
    "#### Sample project\n",
    "- If using `files/imdb` a simple join might do the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d836c258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3f195a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bec949d",
   "metadata": {},
   "source": [
    "## Step 2: Prepare\n",
    "- Explore data\n",
    "- Visualize ideas\n",
    "- Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5d948d",
   "metadata": {},
   "source": [
    "### Step 2.a: Explore data\n",
    "- [`head()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html) Return the first n rows.\n",
    "- [`.shape`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html) Return a tuple representing the dimensionality of the DataFrame.\n",
    "- [`.dtypes`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html) Return the dtypes in the DataFrame.\n",
    "- [`info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html) Print a concise summary of a DataFrame.\n",
    "- [`describe()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) Generate descriptive statistics.\n",
    "- [`isna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html).[`any()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html) Returns if any element is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2673a23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25afee10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2867789a",
   "metadata": {},
   "source": [
    "### Step 2.b: Groupby, Counts and Statistics\n",
    "- Count groups to see the significance across results\n",
    "```Python\n",
    "data.groupby('Gender').count()\n",
    "```\n",
    "- Return the mean of the values over the requested axis.\n",
    "```Python\n",
    "data.groupby('Gender').mean()\n",
    "```\n",
    "- Standard Deviation\n",
    "    - **Standard deviation** is a measure of how dispersed (spread) the data is in relation to the mean.\n",
    "    - Low **standard deviation** means data is close to the mean.\n",
    "    - High **standard deviation** means data is spread out.\n",
    "![Standard deviation](img/std-diagram.png)\n",
    "```Python\n",
    "data.groupby('Gender').std()\n",
    "```\n",
    "- Box plots\n",
    "    - Box plots is a great way to visualize descriptive statistics\n",
    "    - Notice that Q1: 25%, Q2: 50%, Q3: 75%\n",
    "\n",
    "![Box plots](img/box-plot.png)\n",
    "\n",
    "- Make a box plot of the DataFrame columns [plot.box()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.box.html)\n",
    "\n",
    "```Python\n",
    "data.boxplot()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ee14a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c82db67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "137fdfde",
   "metadata": {},
   "source": [
    "### Step 2.c: Visualize data\n",
    "#### Simple Plot\n",
    "```Python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "data = pd.read_csv('files/WorldBank-ATM.CO2E.PC_DS2.csv', index_col=0)\n",
    "data['USA'].plot()\n",
    "```\n",
    "- Adding title and labels\n",
    "    - ```title='Tilte'``` adds the title\n",
    "    - ```xlabel='X label'``` adds or changes the X-label\n",
    "    - ```ylabel='X label'``` adds or changes the Y-label\n",
    "```Python\n",
    "data['USA'].plot(title='US CO2 per capita', ylabel='CO2 (metric tons per capita)')\n",
    "```\n",
    "- Adding ranges\n",
    "    - ```xlim=(min, max)``` or ```xlim=min``` Sets the x-axis range\n",
    "    - ```ylim=(min, max)``` or ```ylim=min``` Sets the y-axis range\n",
    "```Python\n",
    "data['USA'].plot(title='US CO2 per capita', ylabel='CO2 (metric tons per capita)', ylim=0)\n",
    "```\n",
    "- Comparing data\n",
    "```Python\n",
    "data[['USA', 'WLD']].plot(ylim=0)\n",
    "```\n",
    "\n",
    "#### Scatter Plot\n",
    "- Good to see any connection\n",
    "```Python\n",
    "data = pd.read_csv('files/sample_corr.csv')\n",
    "data.plot.scatter(x='x', y='y')\n",
    "```\n",
    "\n",
    "#### Histogram\n",
    "- Identifying quality\n",
    "```Python\n",
    "data = pd.read_csv('files/sample_height.csv')\n",
    "data.plot.hist()\n",
    "```\n",
    "- Identifying outliers\n",
    "```Python\n",
    "data = pd.read_csv('files/sample_age.csv')\n",
    "data.plot.hist()\n",
    "```\n",
    "- Setting bins and figsize\n",
    "```Python\n",
    "data = pd.read_csv('files/WorldBank-ATM.CO2E.PC_DS2.csv', index_col=0)\n",
    "data['USA'].plot.hist(figsize=(20,6), bins=10)\n",
    "```\n",
    "\n",
    "#### Bar Plot\n",
    "- Normal plot\n",
    "```Python\n",
    "data = pd.read_csv('files/WorldBank-ATM.CO2E.PC_DS2.csv', index_col=0)\n",
    "data['USA'].plot.bar()\n",
    "```\n",
    "- Range and columns, figsize and label\n",
    "```Python\n",
    "data[['USA', 'DNK']].loc[2000:].plot.bar(figsize=(20,6), ylabel='CO emmission per capita')\n",
    "```\n",
    "\n",
    "#### Pie Chart\n",
    "- Presenting\n",
    "```Python\n",
    "df = pd.Series(data=[3, 5, 7], index=['Data1', 'Data2', 'Data3'])\n",
    "df.plot.pie()\n",
    "```\n",
    "- Value counts in Pie Charts\n",
    "    - ```colors=<list of colors>```\n",
    "    - ```labels=<list of labels>```\n",
    "    - ```title='<title>'```\n",
    "    - ```ylabel='<label>'```\n",
    "    - ```autopct='%1.1f%%'``` sets percentages on chart\n",
    "```Python\n",
    "(data['USA'] < 17.5).value_counts().plot.pie(colors=['r', 'g'], labels=['>= 17.5', '< 17.5'], title='CO2', autopct='%1.1f%%')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c4c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edbd39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "254042cb",
   "metadata": {},
   "source": [
    "### Step 2.d: Clean data\n",
    "- [`dropna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) Remove missing values.\n",
    "- [`fillna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html) Fill NA/NaN values using the specified method.\n",
    "    - Example: Fill missing values with mean.\n",
    "```Python\n",
    "data = data.fillna(data.mean())\n",
    "```\n",
    "- [`drop_duplicates()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html) Return DataFrame with duplicate rows removed.\n",
    "- Working with time series\n",
    "    - [`reindex()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex.html) Conform Series/DataFrame to new index with optional filling logic.\n",
    "    - [`interpolate()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html) Fill NaN values using an interpolation method.\n",
    "- Resources\n",
    "    - pandas user guide: [Working with missing data](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d6b33d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbc3514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cc1cabe",
   "metadata": {},
   "source": [
    "## Step 3: Analyze\n",
    "- Feature selection\n",
    "- Model selection\n",
    "- Analyze data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b434bc",
   "metadata": {},
   "source": [
    "### Step 3.a: Split into Train and Test\n",
    "- Assign dependent features (those predicting) to `X`\n",
    "- Assign classes (labels/independent features) to `y`\n",
    "- Divide into training and test sets\n",
    "```Python\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837252a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aca1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25b39f4a",
   "metadata": {},
   "source": [
    "### Step 3.b:  Feature Scaling\n",
    "- **Feature Scaling** transforms values in the similar range for machine learning algorithms to behave optimal.\n",
    "- **Feature Scaling** can be a problems for **Machine Learing** algorithms on multiple features spanning in different magnitudes.\n",
    "- **Feature Scaling** can also make it is easier to compare results\n",
    "#### Feature Scaling Techniques\n",
    "- **Normalization** is a special case of **MinMaxScaler**\n",
    "    - **Normalization**: Converts values between 0-1\n",
    "```Python\n",
    "(values - values.min())/(values.max() - values.min())\n",
    "```\n",
    "    - **MinMaxScaler**: Between any values\n",
    "- **Standardization** (**StandardSclaer** from sklearn)\n",
    "    - Mean: 0, StdDev: 1\n",
    "```Python\n",
    "(values - values.mean())/values.std()\n",
    "```\n",
    "    - Less sensitive to outliers\n",
    "\n",
    "#### Normalization\n",
    "- [`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) Transform features by scaling each feature to a given range.\n",
    "- `MinMaxScaler().fit(X_train)` is used to create a scaler.\n",
    "    - Notice: We only do it on training data\n",
    "```Python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "norm = MinMaxScaler().fit(X_train)\n",
    "X_train_norm = norm.transform(X_train)\n",
    "X_test_norm = norm.transform(X_test)\n",
    "```\n",
    "\n",
    "#### Standarization\n",
    "- [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) Standardize features by removing the mean and scaling to unit variance.\n",
    "```Python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler().fit(X_train)\n",
    "X_train_stand = scale.transform(X_train)\n",
    "X_test_stand = scale.transform(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd2edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f60b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "165be8d2",
   "metadata": {},
   "source": [
    "### Step 3.c: Feature Selection\n",
    "- **Feature selection** is about selecting attributes that have the greatest impact towards the **problem** you are solving.\n",
    "\n",
    "#### Why Feature Selection?\n",
    "- Higher accuracy\n",
    "- Simpler models\n",
    "- Reducing overfitting risk\n",
    "\n",
    "#### Feature Selection Techniques\n",
    "\n",
    "##### Filter methods\n",
    "- Independent of Model\n",
    "- Based on scores of statistical\n",
    "- Easy to understand\n",
    "- Good for early feature removal\n",
    "- Low computational requirements\n",
    "\n",
    "##### Examples\n",
    "- [Chi square](https://en.wikipedia.org/wiki/Chi-squared_test)\n",
    "- [Information gain](https://en.wikipedia.org/wiki/Information_gain_in_decision_trees)\n",
    "- [Correlation score](https://en.wikipedia.org/wiki/Correlation_coefficient)\n",
    "- [Correlation Matrix with Heatmap](https://vitalflux.com/correlation-heatmap-with-seaborn-pandas/)\n",
    "\n",
    "##### Wrapper methods\n",
    "- Compare different subsets of features and run the model on them\n",
    "- Basically a search problem\n",
    "\n",
    "##### Examples\n",
    "- [Best-first search](https://en.wikipedia.org/wiki/Best-first_search)\n",
    "- [Random hill-climbing algorithm](https://en.wikipedia.org/wiki/Hill_climbing)\n",
    "- [Forward selection](https://en.wikipedia.org/wiki/Stepwise_regression)\n",
    "- [Backward elimination](https://en.wikipedia.org/wiki/Stepwise_regression)\n",
    "\n",
    "See more on [wikipedia](https://en.wikipedia.org/wiki/Feature_selection#Subset_selection)\n",
    "\n",
    "##### Embedded methods\n",
    "- Find features that contribute most to the accuracy of the model while it is created\n",
    "- Regularization is the most common method - it penalizes higher complexity\n",
    "\n",
    "##### Examples\n",
    "- [LASSO](https://en.wikipedia.org/wiki/Lasso_(statistics))\n",
    "- [Elastic Net](https://en.wikipedia.org/wiki/Elastic_net_regularization)\n",
    "- [Ridge Regression](https://en.wikipedia.org/wiki/Ridge_regression)\n",
    "\n",
    "#### Remove constant and quasi constant features\n",
    "- [`VarianceThreshold`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html) Feature selector that removes all low-variance features.\n",
    "```Python\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold()\n",
    "sel.fit_transform(data)\n",
    "```\n",
    "#### Remove correlated features\n",
    "- The goal is to find and remove correlated features\n",
    "- Calcualte correlation matrix (assign it to `corr_matrix`)\n",
    "- A feature is correlated to any previous features if the following is true\n",
    "    - Notice that we use correlation 0.8\n",
    "```Python\n",
    "corr_features = [feature for feature in corr_matrix.columns if (corr_matrix[feature].iloc[:corr_matrix.columns.get_loc(feature)] > 0.8).any()]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed9c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695249c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9cd6cfb",
   "metadata": {},
   "source": [
    "### Step 3.d: Model Selection\n",
    "- The process of selecting the model among a collection of candidates machine learning models\n",
    "\n",
    "#### Problem type\n",
    "- What kind of problem are you looking into?\n",
    "    - **Classification**: *Predict labels on data with predefined classes*\n",
    "        - Supervised Machine Learning\n",
    "    - **Clustering**: *Identify similarieties between objects and group them in clusters*\n",
    "        - Unsupervised Machine Learning\n",
    "    - **Regression**: *Predict continuous values*\n",
    "        - Supervised Machine Learning\n",
    "- Resource: [Sklearn cheat sheet](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n",
    "\n",
    "#### Model Selection Techniques\n",
    "- **Probabilistic Measures**: Scoring by performance and complexity of model.\n",
    "- **Resampling Methods**: Splitting in sub-train and sub-test datasets and scoring by mean values of repeated runs.\n",
    "\n",
    "#### A few models\n",
    "- [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) Ordinary least squares Linear Regression ([Lesson 08]()).\n",
    "```Python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)\n",
    "y_pred = lin.predict(X_test)\n",
    "r2_score(y_test, y_pred)\n",
    "```\n",
    "- [`SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) C-Support Vector Classification ([Lesson 10]()).\n",
    "```Python\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "svc = LinearSVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n",
    "```\n",
    "- [`KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) Classifier implementing the k-nearest neighbors vote ([Lesson 10]()).\n",
    "```Python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "neigh = KNeighborsClassifier()\n",
    "neigh.fit(X_train.fillna(-1), y_train)\n",
    "y_pred = neigh.predict(X_test.fillna(-1))\n",
    "accuracy_score(y_test, y_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60a6253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac73c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a35dc51",
   "metadata": {},
   "source": [
    "### Step 3.e: Analyze Result\n",
    "This is the main **check-point** of your analysis.\n",
    "- Review the **Problem** and **Data Science problem** you started with.\n",
    "    - The analysis should add value to the **Data Science Problem**\n",
    "    - Sometimes our focus drifts - we need to ensure alignment with original **Problem**.\n",
    "    - Go back to the **Exploration** of the **Problem** - does the result add value to the **Data Science Problem** and the initial **Problem** (which formed the **Data Science Problem**)\n",
    "    - *Example:* As Data Scientist we often find the research itself valuable, but a business is often interested in increasing revenue, customer satisfaction, brand value, or similar business metrics.\n",
    "- Did we learn anything?\n",
    "    - Does the **Data-Driven Insights** add value?\n",
    "    - *Example:* Does it add value to have evidence for: Wealthy people buy more expensive cars.\n",
    "        - This might add you value to confirm this hypothesis, but does it add any value for car manufacturer?\n",
    "- Can we make any valuable insights from our analysis?\n",
    "    - Do we need more/better/different data?\n",
    "    - Can we give any Actionable Data Driven Insights?\n",
    "    - It is always easy to want better and more accurate high quality data.\n",
    "- Do we have the right features?\n",
    "    - Do we need eliminate features?\n",
    "    - Is the data cleaning appropriate?\n",
    "    - Is data quality as expected?\n",
    "- Do we need to try different models?\n",
    "    - Data Analysis is an iterative process\n",
    "    - Simpler models are more powerful\n",
    "- Can result be inconclusive?\n",
    "    - Can we still give recommendations?\n",
    "\n",
    "#### Quote\n",
    "> *“It is a capital mistake to theorize before one has data. Insensibly one begins to twist facts to suit theories, instead of theories to suit facts.”* \n",
    "> - Sherlock Holmes\n",
    " \n",
    "#### Iterative Research Process\n",
    "- **Observation/Question**: Starting point (could be iterative)\n",
    "- **Hypothesis/Claim/Assumption**: Something we believe could be true\n",
    "- **Test/Data collection**: We need to gether relevant data\n",
    "- **Analyze/Evidence**: Based on data collection did we get evidence?\n",
    "    - Can our model predict? (a model is first useful when it can predict)\n",
    "- **Conclude**: *Warning!* E.g.: We can conclude a correlation (this does not mean A causes B)\n",
    "    - Example: Based on the collected data we can see a correlation between A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a455b40a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93af4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98a71ee2",
   "metadata": {},
   "source": [
    "## Step 4: Report\n",
    "- Present findings\n",
    "- Visualize results\n",
    "- Credibility counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94536785",
   "metadata": {},
   "source": [
    "### Step 4.a: Present Findings\n",
    "- You need to *sell* or *tell* a story with the findings.\n",
    "- Who is your **audience**?\n",
    "    - Focus on technical level and interest of your audience\n",
    "    - Speak their language\n",
    "    - Story should make sense to audience\n",
    "    - Examples\n",
    "        - **Team manager**: Might be technical, but often busy and only interested in high-level status and key findings.\n",
    "        - **Data engineer/science team**: Technical exploration and similar interest as you\n",
    "        - **Business stakeholders**: This might be end-customers or collaboration in other business units.\n",
    "- When presenting\n",
    "    - **Goal**: Communicate actionable insights to key stakeholders\n",
    "    - Outline (inspiration):\n",
    "        - **TL;DR** (Too-long; Didn’t read) - clear and concise summary of the content (often one line) that frames key insights in the context of impact on key business metrics.\n",
    "        - Start with your understanding of the business problem\n",
    "        - How does it transform into a Data Science Problem\n",
    "        - How will to measure impact - what business metrics are indicators of results\n",
    "        - What data is available and used\n",
    "        - Presenting hypthosis of reseach\n",
    "        - A visual presentation of the insights (model/analysis/key findings)\n",
    "            - This is where you present the evidence for the insights\n",
    "        - How to use insight and create actions\n",
    "        - Followup and continuous learning increasing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8321ace9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f7cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "009b7151",
   "metadata": {},
   "source": [
    "### Step 4.b: Visualize Results\n",
    "- Telling a story with the data\n",
    "- This is where you convince that the findings/insights are correct\n",
    "- The right visualization is important\n",
    "    - Example: A correlation matrix might give a Data Engineer insights in how findings where discovered, but confuse business partners.\n",
    "\n",
    "#### Resources for visualization\n",
    "- [Seaborn](https://seaborn.pydata.org) Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\n",
    "- [Plotly](https://plotly.com) open-source for analytic apps in Python\n",
    "- [Folium](http://python-visualization.github.io/folium/) makes it easy to visualize data that’s been manipulated in Python on an interactive leaflet map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33111d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ead9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57fb587e",
   "metadata": {},
   "source": [
    "### Step 4.c: Credibility Counts\n",
    "- This is the check point if your research is valid\n",
    "    - Are you hiding findings you did not like (not supporting your hypothesis)?\n",
    "    - Remember it is the long-term relationship that counts\n",
    "- Don't leave out results\n",
    "    - We learn from data and find hidden patterns, to make data-driven decisions, with a long-term perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3b9286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c30c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65c865f1",
   "metadata": {},
   "source": [
    "## Step 5: Actions\n",
    "- Use insights\n",
    "- Measure impact\n",
    "- Main goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c99ed3",
   "metadata": {},
   "source": [
    "### Step 5.a: Use Insights\n",
    "- How do we follow up on the presented **Insights**?\n",
    "- **No one-size-fits-all**: It depends on the **Insights** and **Problem**\n",
    "- *Examples:*\n",
    "    1. **Problem**: What customers are most likely to cancel subscription?\n",
    "        - Say, we have insufficient knowledge of customers, and need to get more, hence we have given recommendations to gather more insights\n",
    "        - But you should still try to add value\n",
    "    2. **Problem**: Here is our data - find valuable insights!\n",
    "        - This is a challenge as there is no given focus\n",
    "        - An iterative process involving the customer can leave you with no surprises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b808aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d403ddb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b1df760",
   "metadata": {},
   "source": [
    "### Step 5.b: Measure Impact\n",
    "- If customer cannot measure impact of your work - they do not know what they pay for.\n",
    "    - If you cannot measure it - you cannot know if hypothesis are correct.\n",
    "    - A model is first valuable when it can be used to predict with some certainty\n",
    "- There should be identified metrics/indicators to evaluate in the report\n",
    "- This can evolve - we learn along the way - or we could be wrong.\n",
    "- How long before we expect to see impact on identified business metrics?\n",
    "- What if we do not see expected impact?\n",
    "- Understanding of metrics\n",
    "    - The metrics we measure are indicators that our hypthesis is correct\n",
    "    - Other aspects can have impact on the result - but you need to identify that\n",
    "    \n",
    "### Main Goal\n",
    "- Your success of a Data Scientist is to create valuable actionable insights\n",
    "\n",
    "#### A great way to think\n",
    "- Any business/organisation can be thought of as a complex system\n",
    "    - Nobody understands it perfectly and it evolves organically\n",
    "- Data describes some aspect of it\n",
    "- It can be thought of as a black-box\n",
    "- Any insights you can bring is like a window that sheds light on what happens inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc4c0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f67725e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
